## Exercice 1.1

Le théoreme d'approximation universerelle dit qu'un réseau de neuronon avec une seul coule couche mais assez grande peux faire nimporte quelle fonction continue sur le domaine des réels. Il ne garenti pas de retrouver les bons poids, car ce sont des bons "approximateurs universelles". Pouvoir appromier c'est pour representer (somme pondérée) une fonction a des moments clés. Apprendre ce fait via les bons poids directement. On utilise des réseau plus de couche cachées car cela permet d'utiliser au mieux les neurones. J'ai pu voir un type d'approximateur de fonction servant en électricité notameent appellé série de Fourier.

## Exercice 1.2
"Le théorème d’approximation universelle affirme qu’un réseau profond peut exactement retrouver les données d’entraînement."
=> Oui il peux totalement le faire SAUF si il s'agit de fonction complete, cela prendrait une infinité de temps si on essaye pas de mettre de limite.

# Partie 2 :